---
title: "Forecasting League of Legends Player Performance through In-Game Metrics and Key Statistics"
subtitle: "A Hybrid Model Predict the KDA for Bilibili Gaming (BLG) team players"
author: 
  - Colin Sihan Yang
thanks: "Code and data are available at: [https://github.com/hoodiexxx/lol_win_rate_prediction](https://github.com/hoodiexxx/lol_win_rate_prediction)."
date: today
date-format: long
abstract: "This paper develops a hybrid model to forecast the 2024 performance of Bilibili Gaming (BLG) team players by analyzing team statistics from the League of Legends Pro League (LPL). The model focuses on predicting the Kill-Death-Assist ratio (KDA) for individual players across different games, leveraging both traditional in-game metrics such as gold difference, kills, assists, and vision score, and advanced variables like total creep score (total CS) to provide a comprehensive view of player performance. By integrating machine learning techniques with esports-specific insights, this model forecasting player KDAs, identifying performance trends, but also offers a clear assessment of individual contributions to the team. The result shows that opinions formed in online discussion or media companies may not reflect the real performace of the players in our model prediction. For instance, our analysis indicates the overhyped performance of Bin in online discussion. It highlights top-performing players while identifying those whose performance may negatively impact the team's success. The findings offer actionable insights, enabling the BLG organization to make informed decisions on player contracts. "
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(palmerpenguins)
library(here)
library(tibble)
library(knitr)
library(arrow)
library(rstanarm)
library(ggplot2)
library(kableExtra)
```

```{r}
#| echo: false
#| warning: false
cleaned_lol_data = read_parquet(here("data/02-analysis_data/cleaned_lol_data.parquet"))
```




# Introduction

In recent years, esports has evolved into a global phenomenon, with professional gaming leagues such as the League of Legends Pro League (LPL) attracting millions of viewers and significant organizational investments. As the competitive landscape intensifies, teams and organizations increasingly rely on data-driven approaches to gain a strategic edge. Among these, predictive analytics has emerged as a powerful tool to evaluate player performance, optimize team strategies, and make informed management decisions.

Bilibili Gaming (BLG), a prominent team in the LPL, faces the challenge of maintaining a competitive roster in the ever-changing meta of League of Legends. Accurate performance forecasting is critical for assessing individual player contributions, identifying areas for improvement, and making decisions about player contracts and roster changes. 

This paper developing a hybrid model that leverages both traditional in-game metrics and advanced variables, such as total creep score (CS, you kill the minion in the game, higher cs means earned more gold from killing minions), to forecast player performance for BLG in the 2024 season. The model specifically focuses on predicting the Kill-Death-Assist ratio (KDA), a widely accepted indicator of individual performance, across various matches. Finally offers actionable insights into player roles and impacts, highlighting those who can consistently carry games and identifying players whose performance may not justify their perceived value.

The remainder of this paper is structured as follows: @sec-data provides an overview of the data. @sec-model provides the modeling approach, including simple and multiple linear regression models and a Bayesian hierarchical model. We then present our results in @sec-result and discuss the implications and limitation, future research directions in @sec-discussion.

The data simulation is done in python 3.9 [@citePython] with the following packages: Numpy [@citeNumPy] and pandas [@citepandas].

The data gathering and analysis is done in R [@citeR] with the following packages: knitr [@knitr], tidyverse [@tidyverse], ggplot2 [@ggplot2], dplyr [@dplyr], arrow [@arrow], here [@here], kableExtra[@citekableextra], and Rstan [@Rstan]

## Estimand

The estimand for this research paper is the predicted Kill-Death-Assist ratio (KDA) for the BLG team players. The prediction is based on quantifying various in-game factors, including total cs, gold earned, vision score, damage to champion, which are used as predictors.






# Data {#sec-data}


## Measurement
	
The dataset we obtain from @oracleselixir_oracles_nodate is accumlated from multiple league of legend esport league like LCS, LEC, LCK, LPL, and the rest of global pro LoL.


The dataset utilized in this study was compiled from multiple professional League of Legends (LoL) esports leagues, including the LCS (North America), LEC (Europe), LCK (South Korea), LPL (China), and other global professional leagues. The data aggregation spans from 2023-2024 (23-24 season) and encompasses a wide variety of matches played at different competitive levels. This diversity ensures a comprehensive representation of professional gameplay styles, strategies, and performances across regions.

Each data point corresponds to a single game of one player, identified by a unique gameid, teamid and playerid and includes contextual information such as the league, split (Spring, Summer, or playoffs), split (Winter, Sping, etc), and year. The dataset captures a rich array of in-game metrics and performance indicators for teams and individual players. Team-level data includes variables such as match result (win/loss), game duration (in minutes and seconds), and pivotal game objectives (e.g., First Blood, First Tower, Baron Nashor, and Dragon counts). These metrics are critical for understanding team performance and macro-level strategies.

Player-level statistics include detailed in-game actions such as kills, deaths, assists, gold earned, damage dealt, and wards placed or cleared. These variables allow for a granular examination of individual contributions to a team's success. Additionally, positional data (e.g., top lane, jungle, mid lane, ADC-bot lane, and support) is included, enabling role-specific analyses. The dataset also tracks champion selections and bans, providing insights into meta trends and drafting strategies over time.

To ensure consistency, all metrics are measured using standardized definitions as provided by the data source, @oracleselixir_oracles_nodate. This source is widely regarded as reliable within the esports analytics community. The dataset is structured to facilitate longitudinal analyses, enabling researchers to inspect trends and patterns across regions, seasons, and competitive tiers. Furthermore, derived metrics, such as the champion xp difference at 25 minutes (xpdiffat25), Gold Difference at 25 minutes (golddiffat25), and Damage Per Minute (dpm), are calculated to provide advanced insights into player and team efficiency.

These variables combined allow researchers to reliably analyze and predict the 23-24 season LPL BLG team's player performance.

However there are limitations in these measurements.The dataset combines data from multiple leagues (LCS, LEC, LCK, LPL, and others), each of which has distinct playstyles, metas, and competitive environments. These regional differences might introduce biases, as strategies or performance metrics effective in one league may not translate directly to another. For instance, the LCK may prioritize slower, macro-focused playstyles, whereas the LPL might exhibit faster, skirmish-heavy games. This variation could confound cross-regional comparisons unless properly controlled for [@tan_aggression_2020].

## Raw Data

The raw data from oracleselixir @oracleselixir_oracles_nodate contains 52 columns, all the column headers are displayed below: 

```{r}
#| echo: false
#| warning: false
raw_data <- read_csv(here("data/01-raw_data/2024_lol_esport.csv"), n_max = 10)


# Get the column names of your data
column_names <- colnames(raw_data)

# Reshape the column names into a matrix with, for example, 4 columns
num_cols <- 3
column_matrix <- matrix(column_names, ncol = num_cols, byrow = TRUE)

# Convert the matrix to a data frame for kable
column_df <- as.data.frame(column_matrix)

# Display in multiple columns with kable
# Generate the table and allow it to span multiple pages
kable(column_df, format = "latex", booktabs = TRUE, longtable = TRUE) %>%
  kable_styling(latex_options = c("repeat_header")) # Adds headers to each new page

```

These columns can be categorized into three types, elements of response variable, numeric predictors, and categorical predictors.

The elements of response variable are: 

- kills: The number of enemy champions defeated by the player.
- deaths: The number of times the player was defeated by opponents.
- assists: The number of assists a player contributes to a teammate's kills.

These three attributes will later be combined to calculate the Kill-Death-Assist ratio (KDA), which serves as the response variable for the model in the cleaned data section @sec-cleaned-data.


Example of Numeric Predictors are:

- totalgold: Total gold earned by the player during the game.
- total.cs: Total number of minions or monsters killed by the player.
- visionscore: A composite measure of vision provided and vision denied.
- damagetochampions: Total damage inflicted by the player on opponents.
- golddiffat25: Gold advantage or deficit compared to the opposing player/team at the 25-minute mark.

Example of categorical predictors are:

- position: The playerâ€™s role in the game (e.g., top, jungle, mid, ADC, support).
- league: The league where the match was played (e.g., LPL, LCK).
- side: team or the blue side or the red side

## Cleaned Data {#sec-cleaned-data}
The cleaned dataset used in this study focuses on matches from the League of Legends Pro League (LPL) involving Bilibili Gaming (BLG) during the 2024 season. To ensure the data aligns with the research objectives, the dataset was filtered to include only games played by BLG, with key variables retained for performance analysis. The cleaning process involved removing rows with missing values and selecting relevant columns, including contextual information such as game ID, league, year, split, and side, as well as in-game performance metrics like kills, deaths, assists, total gold, and vision score. A critical addition to the dataset was the calculation of the Kill-Death-Assist ratio (KDA), a widely used indicator of individual performance. The KDA was derived using the formula:

\begin{align}
KDA = \frac{Kills + Assists}{Max(1, Deaths)}
\end{align}

ensuring robustness even when deaths were zero.

and we mutate the gamelength unit from second into minute.

The cleaned dataset was saved in Parquet formats to support flexibility in analysis and compatibility with various tools. This focused and structured dataset ensures reliability and completeness, providing a robust foundation for forecasting player performance, analyzing trends, and identifying key contributors to the analysis of BLG's players performance.

The first 6 rows of the dataset are displayed in @tbl-cleaned-data.

```{r}
#| label: tbl-cleaned-data
#| tbl-cap: Sample of cleaned league of legend esport data
#| echo: false
#| warning: false
#| tbl-width: 15
#| tbl-height: 8

cleaned_lol_data |>
  select(side, position, playername, champion, kills, deaths, assists, visionscore, totalgold, total.cs) |>
  head(6) |>
  kable(
    col.names = c("side", "position", "playername", "champion", "kills", "deaths", "assists", "visionscore", "totalgold", "total.cs"),
    booktabs = TRUE
    ) 
```

## DATA Insight

### Champion Pool for players

```{r}
#| label: tbl-champion-pool
#| tbl-cap: the table that shows the champion pool for the BLG players
#| echo: false
#| warning: false

# Summarize the data to count champion usage and calculate win rate
top_champions <- cleaned_lol_data |>
  group_by(playername, champion, position) |>
  summarise(
    champion_count = n(),
    win_rate = mean(result == 1), # Proportion of wins for each champion
    .groups = "drop"
  ) |>
  filter(champion_count > 0) |>
  group_by(playername) |>
  slice_max(order_by = champion_count, n = 5) |>
  arrange(playername, desc(champion_count)) |>  mutate(win_rate = round(win_rate, 2))

# Create a formatted table
top_champions |>
  knitr::kable(
    col.names = c("Player Name", "Champion", "Position", "Count", "Win Rate"),
    booktabs = TRUE,
    align = "c"
  )
```

@tbl-champion-pool summarizes the top 5 most played champions for each Bilibili Gaming (BLG) player, including their positions, usage counts, and win rates. It highlights the players' preferences and effectiveness with specific champions, offering insights into individual strengths and team strategies.

- Bin (top lane) favors durable, aggressive champions like Renekton (18 games, 77.8% win rate) and Kennen (12 games, 91.7%). While most of his champions are highly effective, K'Sante has a lower win rate of 54.5%, suggesting Bin may not good at Tank champion. 

- Elk (bot lane) excels on meta ADCs like Kai'Sa, Kalista, and Lucian, all boasting win rates of 80-90%, with consistent performance on utility champions like Senna and Ezreal (77.8%).

- ON (support) shines with engage-heavy champions such as Rell (80%) and Rakan (69.2%), but his Alistar stands out with a perfect 100% win rate, indicating strong synergy in specific scenarios. Wei (substitute jungle) shows exceptional results on niche picks like Maokai, Lillia, and Brand, each with 100% win rates, while his most-played Sejuani achieves 83.3%.

- Xun (main jungle) demonstrates a balanced pool with high win rates on Kindred (83.3%) and Xin Zhao (87.5%), though his performance on Vi (54.5%) is less consistent. Knight (mid lane) showcases versatility, excelling on Corki (92.9%) and Neeko (100%), but his Tristana struggles with a 57.1% win rate.

Wei's (Secondary jungle) limited champion pool suggests fewer games played, with Sejuani (6 games) and Maokai (5 games) leading the count.
Wei appears to specialize in tanky jungle champions and niche picks like Zyra and Brand. it may shows BLG want wei play tank champion to protect other teammates.

Overall, most players exhibit strong performance with their preferred champions, though some picks, like K'Sante and Vi, show room for improvement. These insights can guide BLGâ€™s drafting strategies and optimize player-champion pairings for better outcomes in competitive play.

### Players VisionScore

```{r}
#| label: fig-blg-visionscore
#| fig-cap: BLG players visionscore over game
#| echo: false
#| warning: false
#| fig-width: 15
#| fig-height: 8

# Grouping data by playername and gameid to calculate vision score per game
vision_data <- cleaned_lol_data |>
  group_by(playername, gameid) |>
  summarise(visionscore = sum(visionscore), .groups = "drop")

# Plotting the vision score for each player across games
ggplot(vision_data, aes(x = gameid, y = visionscore, color = playername, group = playername)) +
  geom_line(size = 1) +
  theme_minimal() +
  labs(
    title = "Vision Score by Player Across Games",
    x = "Game ID",
    y = "Vision Score",
    color = "Player Name"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom"
  )
```


@fig-blg-visionscore visualizes the vision scores of individual players on the Bilibili Gaming (BLG) team across multiple games, offering insights into their vision control performance and consistency. Each line represents a player's cumulative vision score over the course of several matches, helping to compare and analyze their contributions to map awareness and team strategy.

Key observations highlight that ON, the team's support player, consistently records the highest vision scores across games. This is expected, as supports typically focus on warding and vision control, critical for map dominance. ELK, the ADC, also shows considerable vision score variability. Other roles, such as Bin (top lane), and Knight (mid lane), have lower and steadier vision scores, aligning with their roles' primary focus on laning and damage output rather than vision control.

\newpage

### Game duration 
```{r}
#| label: fig-blg-game-duration
#| fig-cap: BLG team generally end the game around 30 minutes
#| echo: false
#| warning: false

# Plotting a histogram for game duration in minutes
ggplot(cleaned_lol_data, aes(x = gamelength)) +
  geom_histogram(binwidth = 2, fill = "steelblue", color = "black", alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Distribution of Game Duration",
    x = "Game Duration (minutes)",
    y = "Frequency"
  )
```

@fig-blg-game-duration depicts the distribution of game durations for the Bilibili Gaming (BLG) team, measured in minutes. The graph reveals that most games tend to last between 28 to 36 minutes, with a peak frequency around the 30-minute mark. This suggests that BLG typically ends their games within the expected duration for competitive matches.

\newpage

### players gold earned and players damage

```{r}
#| label: fig-blg-gold-damage
#| fig-cap: In BLG team, ELK is the highest damage and gold earned player.
#| echo: false
#| warning: false
# Reshape the data for comparison
gold_damage_data <- cleaned_lol_data |>
  select(playername, totalgold, damagetochampions) |>
  pivot_longer(
    cols = c(totalgold, damagetochampions),
    names_to = "metric",
    values_to = "value"
  )

# Plot the boxplots for total gold and damage to champions
ggplot(gold_damage_data, aes(x = playername, y = value, fill = metric)) +
  geom_boxplot(outlier.color = "red", outlier.shape = 16, alpha = 0.7) +
  facet_wrap(~ metric, scales = "free_y", labeller = as_labeller(c(
    "totalgold" = "Total Gold Earned",
    "damagetochampions" = "Damage to Champions"
  ))) +
  theme_minimal() +
  labs(
    title = "Comparison of Total Gold Earned and Damage to Champions by Player",
    x = "Player Name",
    y = "Value"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )

```

@fig-blg-gold-damage compare the total gold earned and damage to champions by each player on the Bilibili Gaming (BLG) team, offering insights into their in-game contributions and roles.

Key observations highlight that Elk, the ADC, consistently earns the most gold and deals the highest damage to champions. This reflects the ADC role's reliance on gold to build damage-focused items and their critical role in team fights. However, Wei stands out by earning a comparatively high amount of gold while contributing less damage, suggesting a potential mismatch between resource allocation and damage output. This could indicate a focus on tank or utility-oriented champions or inefficiency in converting gold into impactful performance.


\newpage


# Model {#sec-model}

The goal of our modelling strategy is twofold. Firstly, we aim to accurately predict the player KDA performance based on relevant game data and key influencing factors. Secondly, we seek to evaluate the efficacy of different modeling approachesâ€”from simple linear regression (SLR) to multiple linear regression (MLR) and Bayesian hierarchical modelsâ€”to understand their predictive capabilities and assess the underlying relationships between variables. By comparing these models, we can determine which approach provides the most robust and reliable predictions, while considering the variability and potential uncertainty in the data.

## Precaution for Building Model

According to the KDA formula in @sec-cleaned-data, the response variable KDA is directly depend on three attributes, kills, deaths and assists, so we cannot use kills, deaths and assists as predictors in our model formula Since the response variable is mathematically derived from these three attributes, including kills, deaths, and assists as predictors in the model would create perfect multicollinearity. This means the predictors would have a deterministic relationship with the response variable, violating the assumption of independence between the predictors and the response variable in regression models. For a Bayesian model, this also violates the assumption that the prior information (or likelihood) is not over-specified. In Bayesian inference, incorporating variables that deterministically define the response variable introduces redundancy and inflates the certainty of the posterior distribution, making the model overly confident and prone to poor generalization.


## Basic Simple Linear Regresion Model

### Basic Simple Linear Regression Model Set-Up
\begin{align*}
Y = \beta_0 + \beta_1 \cdot X + \epsilon
\end{align*}

Where:\
\begin{itemize}
\item \( Y \): The dependent variable (response variable) you are trying to predict.
\item \( X \): The independent variable (predictor variable) used to predict \( Y \), in this case, X represent the predictor variable - total CS.
\item \( \beta_0 \): The intercept of the regression line, representing the value of \( Y \) when \( X = 0 \).
\item \( \beta_1 \): The slope of the regression line, representing the change in \( Y \) for a one-unit increase in \( X \).
\item \( \epsilon \): The error term, accounting for the variability in \( Y \) that \( X \) does not explain.
\end{itemize}


### SLR Model
```{r}
#| label: fig-model-SLR
#| fig-cap: "total cs has limited predictive accuracy for league of legend esport players KDA performance."
#| fig-subcap: ["Actual KDA vs Predicted KDA", "predictor total CS vs Actual KDA with linear regression line"]
#| echo: false
#| warning: false
#| layout-nrow: 2

lm_model1 = lm(KDA ~ total.cs, data = cleaned_lol_data)
# summary(lm_model1)
lm1_KDA_predictions = predict(lm_model1, cleaned_lol_data)

# Add predictions and include player information
lm1_data <- cleaned_lol_data |>
  mutate(KDA_predictions = predict(lm_model1),
         playername = as.factor(playername)) # Ensure player names are treated as factors

# Plot predictions vs actual values with player-wise coloring
ggplot(lm1_data, aes(x = KDA, y = KDA_predictions, color = playername)) +
  geom_point(size = 2, alpha = 0.7) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  labs(
    title = "Single Linear Model (Total CS Predictor) for BLG Players",
    x = "Actual KDA",
    y = "Predicted KDA",
    color = "Player Name"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

  # Plot actual KDA vs total CS with regression lines for each player
ggplot(cleaned_lol_data, aes(x = total.cs, y = KDA, color = playername)) +
  geom_point(size = 2, alpha = 0.7) + # Points for actual values
  geom_smooth(method = "lm", se = FALSE, aes(group = playername), size = 1) + # SLR lines per player
  labs(
    title = "Total CS vs. Actual KDA with Regression Lines by Player",
    x = "Total CS",
    y = "KDA",
    color = "Player Name"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

```

In this SLR model, the response variable is KDA and the only one predictor is the total CS. @fig-model-SLR-1 visualizes the relationship between the actual and predicted values of KDA for BLG players, based on a simple linear regression model with total cs as the sole predictor. each points represent individual comparisons between actual and predicted values, with the color of the dots representing different players. The red dashed line represents the line of perfect prediction, where actual values would equal predicted values.

@fig-model-SLR-2 examines the relationship between total CS and KDA for BLG players, with each point representing a game and each player distinguished by color. Separate regression lines for each player highlight role-specific trends. 

The primary concern lies in the evident dispersion of data points, which are widely spread and do not cluster closely around the line of perfect prediction (the dashed red line). This suggestslimited dependence of KDA on total CS, total CS does not adequately explain the variability in KDA. The observed inconsistencies between actual and predicted values indicate that the relationship between KDA and total CS is not sufficiently captured by a linear model with just one predictor.

### Compute R Squared for SLR Model

\begin{align*}
SS_{\text{total}} = \sum_{i=1}^{n} \left( y_i - \bar{y} \right)^2\\
SS_{\text{residual}} = \sum_{i=1}^{n} \left( y_i - \hat{y}_i \right)^2\\
R^2 = 1 - \frac{SS_{\text{residual}}}{SS_{\text{total}}}\\
\text{R-squared} = 0.0008659
\end{align*}



\newpage

## Multiple Linear Regression Model

### Multiple Linear Regression Model Set-up

The formula is:

$$
Y = \beta_0 + \beta_1 \cdot X_1 + \beta_2 \cdot X_2 + \beta_3 \cdot X_3 + \beta_4 \cdot X_4 + \beta_5 \cdot X_5 + \beta_6 \cdot X_6 + \epsilon
$$

Where:

\begin{itemize}
\item \( Y \): The dependent variable (response variable), representing the KDA.
\item \( X_1 \): Side (categorical variable: Blue or Red), representing the team side during the game.
\item \( X_2 \): Vision Score, measuring the player's vision contribution during the game.
\item \( X_3 \): Total Gold, representing the total gold earned by the player.
\item \( X_4 \): Total CS, representing the total creep score of the player.
\item \( X_5 \): Damage to Champions, indicating the total damage dealt to enemy champions.
\item \( X_6 \): Game Duration, representing the length of the game in seconds.
\item \( \beta_0 \): The intercept, representing the expected value of \( Y \) when all predictors are 0.
\item \( \beta_1, \beta_2, \beta_3, \beta_4, \beta_5, \beta_6 \): The coefficients, representing the change in \( Y \) for a one-unit increase in the corresponding predictor while holding other predictors constant.
\item \( \epsilon \): The error term, accounting for the variability in \( Y \) not explained by the predictors.
\end{itemize}

This multiple linear regression model accounts for both categorical and continuous variables to predict the player's **KDA**, capturing the combined influence of gameplay factors such as team side, vision control, resource management, damage output, and game duration.


### MLR

```{r}
#| label: fig-model-MLR
#| fig-cap: "The MLR shows better performance on captured significant variance in players KDA performance."
#| echo: false
#| warning: false

model_MLR = lm(KDA ~ side + visionscore + totalgold + total.cs + damagetochampions + gamelength, data = cleaned_lol_data)


# summary(model_MLR)

model_MLR_KDA_predictions = predict(model_MLR, cleaned_lol_data)

model_MLR_visulization_data <- cleaned_lol_data |>
  mutate(KDA_predictions = predict(lm_model1),
         playername = as.factor(playername)) # Ensure player names are treated as factors

ggplot(model_MLR_visulization_data, aes(x = KDA, y = model_MLR_KDA_predictions, color = playername)) +
  geom_point(size = 2, alpha = 0.7) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  labs(
    title = "Multiple Linear Model (Total CS Predictor) for BLG Players",
    x = "Actual KDA",
    y = "Predicted KDA",
    color = "Player Name"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```


@fig-model-MLR visualizes the results of a Multiple Linear Regression (MLR) model predicting KDA using predictors such as side, vision score, total gold, total CS, damage to champions, and game duration. The x-axis represents the actual KDA values, while the y-axis represents the predicted KDA values. Each dot corresponds to an individual game, with colors indicating different players. The red dashed line represents the perfect prediction line (y=x), where predicted values would perfectly match the actual values.

The model demonstrates an improved ability to capture variance in KDA compared to a simple linear regression model, as evidenced by many points clustering closer to the red dashed line.

### Compute R Squared for SLR Model
\begin{align*}
SS_{\text{total}} = \sum_{i=1}^{n} \left( y_i - \bar{y} \right)^2\\
SS_{\text{residual}} = \sum_{i=1}^{n} \left( y_i - \hat{y}_i \right)^2\\
R^2 = 1 - \frac{SS_{\text{residual}}}{SS_{\text{total}}}\\
\text{R-squared} = 0.337
\end{align*}

There is a strong improvement on the R-squared values, which mean the MLR model have better performance on illustration for the response variable but still reflects limited predictive accuracy, as only 33.7% of the variance in the KDA is explained by the MLR model.


## Bayesian Model

### Bayesian Model Set-UP
\begin{align*}
\text{KDA}_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_1 \cdot \text{visionscore}_i + \beta_2 \cdot \text{totalgold}_i + \beta_3 \cdot \text{totalcs}_i \\
&+ \beta_4 \cdot \text{damagetochampions}_i\\
&+ u_{\text{side}[i]} + u_{\text{gamelength}[i]} + u_{\text{position}[i]} \\
\alpha &\sim \text{Normal}(0, 2.5) \\
\beta_j &\sim \text{Normal}(0, 2.5), \quad j = 1, 2, 3, 4 \\
u_{\text{side}} &\sim \text{Normal}(0, \sigma_{\text{side}}) \\
u_{\text{gamelength}} &\sim \text{Normal}(0, \sigma_{\text{gamelength}}) \\
u_{\text{position}} &\sim \text{Normal}(0, \sigma_{\text{position}})
\end{align*}

This hierarchical Bayesian model is designed to capture both the fixed effects of predictors and the random effects of grouping factors. The response variable is KDA, predictors are visionscore, totalgold, total.cs, damagetochampions, side,gamelength and position. A normal prior with mean 0 and standard deviation 2.5 is set for all coefficients and the intercept, scaled automatically.

### Posterior Predictive Checks 

```{r}
#| echo: false
#| warning: false
# formula = KDA ~ visionscore + totalgold + total.cs + damagetochampions + gamelength + (1 | side)
set.seed(123)

bayesian_model_1 <- readRDS(here("models/bayesian_model_1.rds"))

# pp_check(bayesian_model_1)
# bayesian_model_predictions = posterior_predict(bayesian_model_1, newdata = cleaned_lol_data)
# ss_total <- sum((cleaned_lol_data$KDA - mean(cleaned_lol_data$KDA))^2)
# ss_residual <- sum((cleaned_lol_data$KDA - colMeans(bayesian_model_predictions))^2)
# r_squared <- 1 - (ss_residual / ss_total)
# print(r_squared)
```



```{r}
#| label: fig-bayesian-model
#| fig-cap: "Posterior Predictive Check for the Bayesian Model Predicting pct"
#| echo: false
#| warning: false
pp_check(bayesian_model_1)
```

In @fig-bayesian-model, the posterior predictive check (PPC) plot compares the observed KDA distribution $y$ (dark blue line) with the posterior predictive distributions $y_{rep}$ (lighter blue lines) generated by the Bayesian model. The alignment between the observed and predictive distributions suggests that the model captures the central tendencies and overall variability of KDA effectively. The peak and general shape of the observed distribution are closely mirrored by the simulated predictions, indicating that the included predictorsâ€”vision score, total gold, total CS, damage to champions, position and game length are relevant in explaining the main patterns in KDA.

However, the model shows slight underperformance in capturing extreme values, as evidenced by discrepancies in the tails of the distributions.

In conclusion, the Bayesian model performs well in approximating the central tendencies and variance of KDA, as demonstrated by the close alignment between observed and predictive distributions. However, some refinements may be necessary to improve the model's ability to capture extreme values and better represent the full range of variability in the data.



```{r}
#| echo: false
#| warning: false
# pp_check(bayesian_model_1)

# summary(bayesian_model_1)
# bayesian_model_predictions = posterior_predict(bayesian_model_1, newdata = cleaned_lol_data)
```


```{r}
#| warning: false
#| echo: false
# ss_total <- sum((cleaned_lol_data$KDA - mean(cleaned_lol_data$KDA))^2)
# ss_residual <- sum((cleaned_lol_data$KDA - colMeans(bayesian_model_predictions))^2)
# r_squared <- 1 - (ss_residual / ss_total)
```

### Train Test Validation
we implemented a train-test split validation approach to evaluate the performance of a Bayesian hierarchical model predicting KDA for BLG players. The dataset was divided into training (70%) and test (30%) sets to fit and validate the model, respectively. We used the stan_glmer function to fit the model on the training data, with predictors including vision score, total gold, total CS, damage to champions, position and game length. After training, we test the model by generated predictions on the test set and calculated an R squared value to quantify the model's predictive accuracy. 

```{r}
#| echo: false
#| warning: false
train_data = read_parquet(here("data/02-analysis_data/train_data.parquet"))
test_data = read_parquet(here("data/02-analysis_data/test_data.parquet"))

bayesian_model_train = readRDS(here("models/bayesian_model_train.rds"))

predictions <- posterior_predict(bayesian_model_train, newdata = test_data)

ss_total <- sum((test_data$KDA - mean(test_data$KDA))^2)
ss_residual <- sum((test_data$KDA - colMeans(predictions))^2)
r_squared <- 1 - (ss_residual / ss_total)

# R-Squared: 0.6281344
```



\begin{align}
SS_{\text{total}} = \sum_{i=1}^{n} \left( y_i - \bar{y} \right)^2\\
SS_{\text{residual}} = \sum_{i=1}^{n} \left( y_i - \hat{y}_i \right)^2\\
R^2 = 1 - \frac{SS_{\text{residual}}}{SS_{\text{total}}}\\
\text{R-squared} = 0.6281344
\end{align}

Where:\
\begin{itemize}
    \item \( y_i \) represents the actual values,
    \item \( \bar{y} \) is the mean of the actual values,
    \item \( \hat{y}_i \) are the predicted values,
    \item \( SS_{\text{total}} \) is the total sum of squares,
    \item \( SS_{\text{residual}} \) is the sum of squared residuals.
\end{itemize}

An $R^{2}$ value of 0.6281 indicates that the Bayesian model explains approximately 62.8% of the variability in the test dataset's KDA values. This suggests that the predictors used in the modelâ€”such as vision score, total gold, total CS, damage to champions, and the random effectsâ€”capture a substantial portion of the variation in KDA. The $R^{2}$ value show the bayesian model has strong improvement compare to previous SLR and MLR model.

```{r}
#| label: fig-bayesian-model-actual-predict
#| fig-cap: "The Bayesian Model Accurately Predicts the Testing Dataset"
#| echo: false
#| warning: false
#| fig-height: 8
#| fig-width: 20

plot(test_data$KDA, colMeans(predictions), 
     xlab = "Actual players KDA", 
     ylab = "Predicted players KDA", 
     main = "Multiple Predictors and random effects for players KDA in Bayesian Model")
abline(0, 1, col = "red")
```

By visual checking actual pct and predicted pct plot in @fig-bayesian-model-actual-predict, the points are plotted against a 45-degree line, which represents the ideal scenario where predicted values match the actual values perfectly. As there are a single indentifiable pattern and the dots are random scatter around the line. It provide a strong evidence that the model is valid.


```{r}
#| label: fig-bayesian-model-residual
#| fig-cap: "Bayesian Model Residuals Appear to Show No Trends"
#| echo: false
#| warning: false
residuals <- test_data$KDA - colMeans(predictions)
plot(colMeans(predictions), residuals, 
     xlab = "Predicted Values", 
     ylab = "Residuals", 
     main = "Residual for the Bayesian Hierarchical Model Predictions")
abline(h = 0, col = "red")
```

In addition, the residual plot in @fig-bayesian-model-residual is fairly centered around zero with no major trend, suggesting that the model is not heavily biased in its predictions. 

In conclusion, from the visual checks from the predicted vs. actual plot and the residual plot, there is no robust evidence that the Bayesian model is overfitting. It appears to generalize well to the data it was trained on without showing signs of capturing noise or irrelevant patterns.  



## Model justification
We chose  vision score, total gold, total CS, damage to champions, position and game length as key in-game metrics and contextual variability to predict KDA. The visualizations in @fig-blg-visionscore highlight significant relationships between predictors and performance. For instance, vision score, which varies widely among players, particularly supports like ON, reflects role-specific contributions to team performance, justifying its inclusion as a fixed effect. Similarly, metrics such as total gold and damage to champions, shown to vary by role (e.g., Elk consistently excelling as an ADC) in @fig-blg-gold-damage, emphasizing the importance of resource generation and damage output in predicting KDA. Including these predictors ensures that the model captures individual player contributions effectively.

Random effects for team side, position, and game length further enhance the model by accounting for contextual variability. The histogram in @fig-blg-game-duration of game durations shows that while most games last 30-35 minutes, variability exists, necessitating its inclusion to adjust for its impact on player performance. The hierarchical structure also captures differences in roles and sides, ensuring the model adapts to diverse scenarios. Overall, the chosen model balances fixed effects for key performance metrics with random effects for contextual factors, ensuring robust and accurate KDA predictions.

# Result {#sec-result}

```{r}
#| label: fig-bayesian-model-CI
#| fig-cap: "Bin is the superstar of BLG team, but show disappointed KDA prediction in 95% credible interval"
#| echo: false
#| warning: false
# Plot random effects
# Generate posterior predictions for all players
posterior_predictions <- posterior_predict(bayesian_model_1, newdata = cleaned_lol_data)

# Calculate player-specific credible intervals
credible_intervals <- cleaned_lol_data %>%
  mutate(predicted_KDA = colMeans(posterior_predictions)) %>% # Mean prediction for each observation
  group_by(playername) %>%
  summarise(
    mean_KDA = mean(predicted_KDA), # Average predicted KDA per player
    lower_95 = quantile(predicted_KDA, 0.025), # 2.5th percentile
    upper_95 = quantile(predicted_KDA, 0.975)  # 97.5th percentile
  )

# Plot credible intervals with different colors for each player
ggplot(credible_intervals, aes(x = playername, y = mean_KDA, color = playername)) +
  geom_point(size = 3) + # Mean KDA
  geom_errorbar(aes(ymin = lower_95, ymax = upper_95), width = 0.2, size = 1) + # Credible intervals
  labs(
    title = "Posterior Credible Intervals for KDA by Player",
    x = "Player Name",
    y = "Predicted KDA",
    color = "Player Name"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none" # Hide legend if redundant
  )

```

This plot @fig-bayesian-model-CI illustrates the posterior credible intervals for the predicted KDA of each player on the BLG team, based on the Bayesian mixed-effects model. The mean predicted KDA for each player is represented by the points, while the vertical lines show the 95% credible intervals. Each player is assigned a distinct color, making it easier to distinguish between their predictions and associated uncertainties. 

The credible intervals vary in width across players, reflecting differences in the model's certainty about their performance. Players like Elk and Knight, who play key roles such as ADC and Mid Lane, have slightly higher predicted KDA values with credible intervals that extend across a moderate range, indicating variability in their potential performance. On the other hand, roles like Support (ON) and Jungle (Xun) also show notable ranges in their credible intervals, reflecting the dynamic nature of their contributions during games. 

One thing worth mentioning is that Bin, the superstar Top Lane player of the BLG team, shows a disappointing KDA prediction within his 95% credible interval. Despite his reputation and the high expectations from media and fans, the model's prediction suggests that Bin's actual performance may not align with the hype. This could indicate that Bin is overrated by his supporters and might be more dependent on his teammates than previously thought. The data implies that Bin is often carried by his team, highlighting a significant gap between his perceived status and actual contributions. This reinforces the importance of using objective metrics to assess individual player impact rather than relying solely on public perception or narrative @arevalo-ostberg_top_nodate.

```{r}
#| label: tbl-bayesian-model-result-summary
#| tbl-cap: "Bayesian Model Result Summary"
#| echo: false
#| warning: false

# Generate posterior predictions for the cleaned data
predictions_KDA = posterior_predict(bayesian_model_1, newdata = cleaned_lol_data)

# Calculate the predicted means and credible intervals
predicted_means = round(colMeans(predictions_KDA), 2)
predicted_intervals = round(apply(predictions_KDA, 2, quantile, probs = c(0.025, 0.975)), 2)

# Combine the results with the actual data
result_summary = data.frame(
  Player_Name = cleaned_lol_data$playername,
  Actual_KDA = round(cleaned_lol_data$KDA, 2),
  Predicted_KDA = predicted_means,
  Lower_CI = predicted_intervals[1, ],
  Upper_CI = predicted_intervals[2, ]
)

# Display the summary table
kable(head(result_summary, 10), 
      col.names = c("Player Name", 
                    "Actual KDA", 
                    "Predicted KDA", 
                    "Lower Bound Credible Interval", 
                    "Upper Bound Credible Interval"),
      caption = "Summary of Actual vs Predicted KDA with 95% Credible Intervals")

```

@tbl-bayesian-model-result-summary provides a summary of the actual KDA, predicted KDA, and the 95% credible intervals for the predictions of BLG players. The results reveal varying levels of alignment between the actual and predicted KDA.

```{r}
#| label: fig-bayesian-model-result-CI
#| fig-cap: "The Model Shows a Moderate-Well Alignment Between Actual and Predicted KDA"
#| echo: false
#| warning: false

ggplot(result_summary, aes(x = Actual_KDA, y = Predicted_KDA, color = Player_Name)) +
  geom_point(size = 3, alpha = 0.7) + # Points for predictions, colored by player
  geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI), width = 0.2, size = 0.8, alpha = 0.8) + # Error bars
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed", size = 1) + # Perfect prediction line
  labs(
    title = "KDA Prediction Result by Player",
    x = "Actual KDA",
    y = "Predicted KDA",
    color = "Player Name"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom"
  )
```

@fig-bayesian-model-result-CI visualizes the predicted KDA values and their associated 95% credible intervals for each BLG player, compared against their actual KDA. The points represent the mean predicted KDA, color-coded by player name, while the vertical error bars show the uncertainty in the predictions (credible intervals). The red dashed line represents perfect prediction, where the predicted KDA equals the actual KDA. Most predictions cluster around the red line, indicating that the Bayesian model aligns reasonably well with the actual KDA values. However, there are notable deviations, especially in cases of high actual KDA values. These deviations are likely due to the scarcity of data for games with extremely high KDA, leading to greater uncertainty in the model's predictions for these cases. This emphasizes the importance of accounting for data imbalance in future modeling efforts.

# Discussion {#sec-discussion} 

## Ethics, Sportsmanship, and the Broader Impact of League of Legends Esports
League of Legends (LoL) esports is more than a competitive gaming platform; it serves as a cultural and ethical touchpoint that influences players, fans, and the broader entertainment industry. The competitive environment of LoL is not only about winning games but also about fostering sportsmanship and collaboration. Professional players are expected to uphold ethical standards, demonstrating respect for opponents, referees, and fans, regardless of the game's outcome. This culture of respect and fair play is crucial, as it sets a positive example for the millions of young fans who view these players as role models. Encouraging good sportsmanship in esports reinforces values such as teamwork, discipline, and perseverance, which are important in both gaming and broader life contexts.

Moreover, League of Legends esports contributes significantly to the global entertainment industry, combining intense competition with narrative-driven content to create a highly engaging spectator experience. Events like the World Championship attract millions of viewers, showcasing esports as a legitimate entertainment medium on par with traditional sports. This global reach provides opportunities to inspire young generations by emphasizing the importance of never giving up, learning from failures, and working towards personal and collective goals. 
## Summary of Findings

This study develops a predictive model to assess player performance for Bilibili Gaming (BLG) in the League of Legends Pro League (LPL). The findings reveal that metrics such as vision score, total gold, total CS, damage to champions, and game side significantly contribute to predicting \( KDA \). The Bayesian mixed-effects model achieved an $R^{2}$ of 0.63, demonstrating strong predictive accuracy and capturing substantial variability in player performance.

The analysis highlights that players like Elk and Knight consistently show high predicted \( KDA \) values with narrower credible intervals, indicating strong and stable contributions. Conversely, Bin, despite having a significantly higher contract than Elk, demonstrates lower predicted performance with wide credible intervals, suggesting inconsistencies and greater reliance on teammates. This disparity between investment and contribution indicates potential inefficiencies in resource allocation. It is recommended that BLGâ€™s management reassess contract structures and performance metrics to ensure alignment between player compensation and impact. Additionally, It is recommended that BLGâ€™s management lower Bin's in-game priority and focus team resources on higher-impact players like Elk and Knight. This approach could help mitigate Binâ€™s negative impact on team performance and ensure the teamâ€™s overall strategy remains efficient and competitive. 

## Sources of Bias

Several sources of bias may affect the findings and predictions of this study Based on the figures in @sec-data. First, the dataset relies heavily on historical in-game metrics from the League of Legends Pro League (LPL). These metrics may not fully capture all dimensions of player performance, such as intangible contributions like shot-calling, morale boosting, or adapting to unforeseen situations during matches. Consequently, the model may undervalue players who excel in these non-quantifiable aspects of gameplay.

Second, the inclusion of only certain predictors, such as vision score, total CS, and damage to champions, introduces potential bias by excluding other relevant variables, such as synergy with teammates, champion pool diversity, or adaptability to meta changes. This limited scope could lead to an overemphasis on specific roles or playstyles, particularly those that align well with the chosen predictors.

Third, the dataset may reflect team-specific dynamics or strategies that do not generalize well across all competitive scenarios. For example, players like Bin may appear to underperform relative to metrics like KDA but could be fulfilling strategic roles not reflected in the data. Additionally, external factors, such as the influence of the blue-side advantage or variability in opponent strength, may introduce bias if not adequately controlled for.

Finally, the predictive model assumes that past performance reliably predicts future outcomes, which may not always hold true in a rapidly evolving esports environment. Changes in game patches, meta shifts, or individual player development can significantly alter performance, potentially leading to inaccuracies in predictions. Acknowledging and addressing these biases is essential for refining the model and improving its applicability in real-world decision-making for esports teams.

## Limitations of the Model{#sec-model-limitations} 

The Bayesian mixed-effects model, while effective, has several inherent limitations. First, it relies on a predefined set of in-game metrics, such as vision score, total CS, total gold, damage to champions, and game length. These metrics, while significant, do not fully account for intangible factors like leadership, communication, or decision-making, which are critical components of a playerâ€™s performance. As a result, the model may undervalue players whose contributions extend beyond quantifiable metrics.

Second, the model assumes a linear relationship between predictors and the response variable (KDA), which may oversimplify the complex interactions in competitive gameplay. Non-linear dynamics, such as synergistic interactions between players or champion-specific performance nuances, are not explicitly captured, potentially limiting the modelâ€™s ability to reflect real-world complexities.

Lastly, the model is trained on data from a single team, BLG, in the LPL, which could restrict its generalizability. Regional differences in playstyle, team dynamics, or meta-strategies may lead to variations in predictor-response relationships that the model is not designed to address. As a result, its applicability outside this specific context is limited.

## Limitation of the Prediction 
In @sec-result, the predictive accuracy of the model is subject to certain constraints that impact its reliability. First, predictions are heavily influenced by historical data and may fail to account for future changes, such as meta shifts, patch updates, or evolving team strategies. Players like Bin, whose performance appears inconsistent in the current data, might improve under different conditions, but such adjustments are beyond the scope of the model's predictions.

Second, predictions are affected by biases and variability in the data. Factors like opponent strength, game-side advantages, and external influences (e.g., player fatigue or morale) are not fully controlled for, which can introduce noise and uncertainty. This is reflected in the broad credible intervals for some players, particularly those with inconsistent performances, limiting the precision of the forecasts.

Finally, the predictions focus on quantifiable metrics like KDA, which may not fully encapsulate a player's overall contribution to team success. For example, players with lower KDA but critical strategic roles, such as shot-calling, may appear undervalued in the predictions. Future iterations could incorporate additional predictors, such as champion pool diversity or team synergy, to improve the model's predictive capacity and better capture the multifaceted nature of player performance.


## Future Directions 
Future research could expand on this study by incorporating additional predictors to better capture the multifaceted nature of player performance in esports. Metrics such as champion pool diversity, synergy with teammates, and adaptability to meta shifts could provide a more comprehensive understanding of individual contributions. Exploring non-linear relationships and interaction effects among in-game metrics may also enhance the model's ability to reflect the complexities of competitive gameplay. Additionally, validating the model across different teams, regions, and competitive levels could improve its generalizability and robustness. Integrating real-time data or patch-specific adjustments would further refine predictions, making them more adaptable to the dynamic nature of esports. Lastly, examining the broader implications of performance predictions, such as their influence on player development, team strategies, and fan engagement, could provide valuable insights for both academics and practitioners in the esports industry.

\newpage

\appendix

# Appendix {-}

# Model Detail

## Trace Plot

```{r}
#| label: fig-bayesian-model-trace-plot
#| fig-cap: "The figure capture the trend of actual player KDA performance"
#| echo: false
#| warning: false

# Add predictions to the data
bayesian_model_predictions_geoline = posterior_predict(bayesian_model_1, newdata = cleaned_lol_data)
geo_line_visualization_dataset = cleaned_lol_data
geo_line_visualization_dataset$predicted_KDA <- apply(bayesian_model_predictions_geoline, 2, mean) # Take the mean of posterior predictions

# Create a visualization with actual vs. predicted values
ggplot(geo_line_visualization_dataset, aes(x = damagetochampions)) +
  geom_line(aes(y = KDA, color = "Actual"), size = 1) + # Line for actual values
  geom_line(aes(y = predicted_KDA, color = "Predicted"), size = 1, linetype = "dashed") + # Line for predicted values
  labs(
    title = "Actual vs Predicted KDA",
    x = "damagetochampions",
    y = "KDA",
    color = "Legend"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom"
  )

```

@fig-bayesian-model-trace-plot visualizes the comparison between the actual KDA (Kill-Death-Assist ratio) and the predicted KDA based on the Bayesian model, with the x-axis representing damage dealt to champions. The solid red line represents the actual KDA trends, while the dashed blue line captures the model's predictions. The visualization indicates a general alignment between the predicted and actual KDA values, particularly for lower damage ranges, suggesting that the model captures key patterns in player performance effectively. However, as the damage to champions increases, discrepancies between the actual and predicted KDA become more pronounced, reflecting potential model limitations in extreme gameplay scenarios. This highlights areas where additional predictors or refinements may improve the modelâ€™s performance for high-damage games.

\newpage

# Result(Categorical response variable) by Logistics Regression Model

```{r}
#| label: fig-bayesian-logistic-regreesion-plot
#| fig-cap: "The figure shows most of result prediction are correct"
#| echo: false
#| warning: false
#| fig-height: 12
#| fig-width: 15
result_prediction_model = readRDS(here("models/first_win_rate_prediction_model.rds"))
model_data = read_parquet(here("data/02-analysis_data/cleaned_lol_data.parquet"))
predicted_probabilities <- posterior_predict(result_prediction_model, newdata = model_data)

# Calculate mean probabilities for each observation
mean_probabilities <- colMeans(predicted_probabilities)

# Classify predictions
predicted_classes <- ifelse(mean_probabilities > 0.5, 1, 0)


# Calculate accuracy
accuracy <- mean(predicted_classes == as.numeric(as.character(model_data$result)))
# print(paste("Accuracy:", accuracy))

model_data$predicted_class <- as.factor(predicted_classes)  # Add predicted class
model_data$actual_class <- as.factor(as.numeric(as.character(model_data$result)))  # Convert actual class to factor

model_data$combined_label <- with(model_data, ifelse(
  actual_class == predicted_class & actual_class == "1", "Win - Correct",
  ifelse(actual_class != predicted_class & actual_class == "1", "Win - Incorrect",
    ifelse(actual_class == predicted_class & actual_class == "0", "Lose - Correct", "Lose - Incorrect")
  )
))

# Plot the combined labels with different colors
ggplot(model_data, aes(x = total.cs, y = kills, color = combined_label)) +
  geom_point(size = 3, alpha = 0.8) +  # Scatter plot points
  scale_color_manual(
    values = c(
      "Win - Correct" = "blue",
      "Win - Incorrect" = "lightblue",
      "Lose - Correct" = "green",
      "Lose - Incorrect" = "red"
    )
  ) +
  labs(
    title = "Prediction Results: Win/Lose and Accuracy",
    x = "Total CS",
    y = "Kills",
    color = "Prediction Result"
  ) +
  theme_minimal() +
  theme(legend.position = "right")
```

@fig-bayesian-logistic-regreesion-plot illustrates the classification accuracy of a Bayesian model predicting game outcomes (win/loss) for BLG players based on total creep score (CS) and kills. Each data point represents a game, with the x-axis showing total CS and the y-axis showing kills. Points are color-coded according to the prediction results: blue for "Win - Correct," light blue for "Win - Incorrect," green for "Lose - Correct," and red for "Lose - Incorrect."

The distribution reveals that most predictions align with actual results (indicated by the dominance of blue and green points), suggesting that the model performs reasonably well. However, some incorrect classifications (light blue and red points) highlight areas where the model struggles, particularly in games with extreme values of kills or CS. This discrepancy may indicate the need for additional predictors or refined modeling to capture nuances in performance and outcomes. The visualization effectively communicates the model's predictive capabilities and areas for potential improvement.


```{r}
#| label: fig-bayesian-logistic-win-rate-accuracy
#| fig-cap: "the Actual Win Rate, Predicted Win Rate and Prediction Accuracy"
#| echo: false
#| warning: false


# Calculate win rate and accuracy
library(dplyr)
library(ggplot2)

# Add predicted and actual results to the dataset
model_data$predicted_class <- as.factor(predicted_classes)  # Predicted win/loss
model_data$actual_class <- as.factor(as.numeric(as.character(model_data$result)))  # Actual win/loss

# Calculate win rate for actual and predicted
win_rate_actual <- mean(as.numeric(as.character(model_data$result)) == 1)
win_rate_predicted <- mean(predicted_classes == 1)

# Calculate prediction accuracy
accuracy <- mean(predicted_classes == as.numeric(as.character(model_data$result)))

# Print win rate and accuracy
# cat("Actual Win Rate:", round(win_rate_actual * 100, 2), "%\n")
# cat("Predicted Win Rate:", round(win_rate_predicted * 100, 2), "%\n")
# cat("Prediction Accuracy:", round(accuracy * 100, 2), "%\n")

# Prepare data for visualization
win_accuracy_data <- data.frame(
  Metric = c("Actual Win Rate", "Predicted Win Rate", "Prediction Accuracy"),
  Percentage = c(win_rate_actual * 100, win_rate_predicted * 100, accuracy * 100)
)

# Visualization
ggplot(win_accuracy_data, aes(x = Metric, y = Percentage, fill = Metric)) +
  geom_bar(stat = "identity", color = "black", width = 0.6) +
  labs(
    title = "Win Rate and Prediction Accuracy",
    x = "",
    y = "Percentage (%)"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 45, hjust = 1)
  )


```

@fig-bayesian-logistic-win-rate-accuracy provides a comparison between the actual win rate, predicted win rate, and overall prediction accuracy of the model. The actual win rate represents the proportion of games that the BLG team truly won, while the predicted win rate reflects the proportion of games that the model classified as wins. The prediction accuracy illustrates how well the model aligns with the actual game outcomes, showing the percentage of correct predictions. The chart reveals that the predicted win rate is closely aligned with the actual win rate, and the prediction accuracy is relatively high, indicating that the model performs well in capturing the win/loss dynamics in the dataset. This suggests the model has practical utility for predicting match outcomes based on the available features.




# Ideal Survey

An ideal survey for studying esports performance and its impact on players, teams, and audiences would involve a structured and systematic approach. The goal is to collect comprehensive, representative, and high-quality data to inform further research and practical decision-making. Below is a detailed breakdown of the components of this survey:

## Sampling Frame

The sampling frame would include key stakeholders in the esports ecosystem, such as professional players, coaches, team managers, analysts, and dedicated fans. The survey would target participants across different regions, leagues (e.g., LPL, LCK, LEC, and LCS), and tiers of competitive play to ensure diversity and inclusivity. By including individuals with varied roles and perspectives, the survey would capture the multifaceted nature of esports performance and its broader implications.

## Survey Sending Process

The survey would be disseminated via multiple channels to maximize reach and response rates. Online platforms such as email, social media, and messaging apps like Discord and WhatsApp would be primary distribution methods for participants already active in esports communities. Partnerships with esports organizations, event organizers, and content creators would help promote the survey to a broader audience. Reminders would be sent periodically to encourage participation while ensuring ethical practices, such as respecting participants' privacy and obtaining informed consent.

## Sampling Methodology

The survey would adopt a stratified random sampling methodology to ensure representation across different stakeholder groups and regions. For example, participants would be grouped by roles (players, coaches, fans) and leagues, and then randomly selected from each group. This approach would mitigate biases and provide a balanced dataset that reflects the diversity of the esports ecosystem. Additionally, oversampling underrepresented groups, such as amateur players or smaller regional leagues, would ensure their voices are adequately captured.

## Survey Implementation & Question Creation

The survey would be implemented using a user-friendly online platform to ensure accessibility. Questions would be designed to address both qualitative and quantitative aspects of esports performance. For instance:

- **Quantitative Questions**: Metrics-based questions, such as training hours, in-game performance statistics, and viewership demographics.
- **Qualitative Questions**: Open-ended questions on the challenges faced by players, the impact of game patches, or perceptions of team dynamics and fan engagement.

Pilot testing would be conducted to refine the survey, ensuring questions are clear, unbiased, and aligned with the research objectives. Additionally, anonymity and confidentiality would be emphasized to encourage honest and accurate responses.

This structured approach to survey design and implementation would enable the collection of comprehensive and reliable data, supporting future research and actionable insights in the esports industry.

## Survey Questions

List of all of the questions:

1. Select your most play position in League of Legend
   - Top
   - Jungle 
   - Mid 
   - Bot 
   - Support

2. Please select your highest rank level
    - Unranked  
    - Iron  
    - Bronze  
    - Silver  
    - Gold  
    - Platinum  
    - Diamond  
    - Master  
    - Grandmaster  
    - Challenger

3. Please select the highest degree of education you have obtained
    - Summonerâ€™s Rift (Ranked/Normal)  
    - ARAM (All Random All Mid)  
    - Teamfight Tactics (TFT)  
    - Ultimate Spellbook  
    - Nexus Blitz  
    - Custom Games  
    - Other (Please specify): __________

4. Which League of Legends esports league do you primarily watch, subscribe to, or focus on?

    - League of Legends Pro League (LPL)  
    - League of Legends Champions Korea (LCK)  
    - League of Legends European Championship (LEC)  
    - League Championship Series (LCS)  
    - Pacific Championship Series (PCS)  
    - Vietnam Championship Series (VCS)  
    - League of Legends Continental League (LCL)  
    - CBLOL (Brazilian League of Legends Championship)  
    - LJL (League of Legends Japan League)  
    - Other (Please specify): __________


5. Which is your favorite League of Legends (LoL) esports team?
    - T1  
    - JD Gaming (JDG)  
    - Bilibili Gaming (BLG)  
    - Gen.G  
    - G2 Esports  
    - Fnatic (FNC)  
    - Cloud9 (C9)  
    - Royal Never Give Up (RNG)  
    - DAMWON Gaming (DWG KIA)  
    - Team Liquid (TL)  
    - Other (Please specify): __________

6. Who do you consider to be the GOAT (Greatest of All Time) of League of Legends?
    - Faker (T1)  
    - Uzi (RNG)  
    - Bin (BLG)

    - Caps (G2 Esports)  
    - Other (Please specify): __________  
    - Iâ€™m not sure / I donâ€™t have an opinion. 

7. Who do you consider to be the best Top Laner of all time in League of Legends?
    - TheShy (Weibo Gaming)  
    - Zeus (T1) 
    
    - Marin (Retired)  
    - Nuguri (Retired)  
    - Smeb (Retired)  
    - Bin (Bilibili Gaming)  
    - 369 (JD Gaming)  
    - Impact (Evil Geniuses)  
    - Other (Please specify): __________  
    - Iâ€™m not sure / I donâ€™t have an opinion.  

8. How long have you been playing League of Legends?
    - Less than 6 months  
    - 6 months to 1 year  
    - 1â€“3 years  
    - 3â€“5 years  
    - 5â€“10 years  
    - Over 10 years  

9. How often do you watch professional League of Legends games?
    - Rarely or never
    - A few matches per season
    - Regularly during major tournaments (e.g., Worlds, MSI)
    - Frequently during regional leagues (e.g., LPL, LCK)
    - I watch almost all professional games

10. Do you feel League of Legends has positively impacted your personal skills or habits?
    - Yes, it has improved my teamwork and communication skills
    - Yes, it has enhanced my problem-solving and decision-making abilities
    - Yes, it has boosted my resilience and mental toughness
    - No, I donâ€™t feel it has impacted me personally
    - Other (Please specify): __________





\newpage


# References


